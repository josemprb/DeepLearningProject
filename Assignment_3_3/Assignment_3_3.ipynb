{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_3_3.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"cCwL6XL2v5jN","colab_type":"text"},"cell_type":"markdown","source":["### The German Traffic Sign Benchmark\n","\n","Student Name 1: Matteo Anelli\n","\n","Student Name 2: José Manuel Pérez"]},{"metadata":{"id":"H-d1rPGfv5jO","colab_type":"text"},"cell_type":"markdown","source":["Download full data set from http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset"]},{"metadata":{"id":"i4VuunJav5jP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"82f576fb-de12-49d3-f73a-33a2a314eca7"},"cell_type":"code","source":["!wget -c http://benchmark.ini.rub.de/Dataset_GTSDB/FullIJCNN2013.zip\n","!unzip FullIJCNN2013.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-04-04 09:50:28--  http://benchmark.ini.rub.de/Dataset_GTSDB/FullIJCNN2013.zip\n","Resolving benchmark.ini.rub.de (benchmark.ini.rub.de)... 134.147.122.15\n","Connecting to benchmark.ini.rub.de (benchmark.ini.rub.de)|134.147.122.15|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1661866983 (1.5G) [application/zip]\n","Saving to: ‘FullIJCNN2013.zip’\n","\n","FullIJCNN2013.zip    53%[=========>          ] 854.27M  4.02MB/s    eta 2m 56s "],"name":"stdout"}]},{"metadata":{"id":"EjK2WZ0rv5jU","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import cv2\n","\n","IMG_HEIGHT = 600\n","SIGN_SIZE = (224, 224)\n","\n","# Function for reading the images\n","def readImages(rootpath, images_range, signs_range):\n","    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n","    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n","    Returns:   list of images, list of corresponding labels'''\n","    images = {} # original image\n","    scales = {} # original scale\n","    for num in images_range:\n","        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n","        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n","        scale = IMG_HEIGHT / float(img.shape[0])\n","        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n","        images.setdefault(filename,[]).append(img_resized)\n","        scales.setdefault(filename,[]).append(scale)\n","\n","    files = [] # filenames\n","    signs = [] # traffic sign image\n","    bboxes = [] # corresponding box detection\n","    labels = [] # traffic sign type\n","    data = np.genfromtxt(rootpath + '/' + 'gt.txt', delimiter=';', dtype=str, usecols=range(0, 6))\n","    for elem in signs_range:\n","        filename = rootpath + '/' + data[elem][0]\n","        img = images.get(filename)[0]\n","        scale = scales.get(filename)[0]\n","        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n","        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n","        sign_resized = cv2.resize(sign, SIGN_SIZE)\n","        files.append(filename)\n","        signs.append(sign_resized)\n","        bboxes.append(bbox)\n","        labels.append(data[elem][5])\n","    return images, files, signs, bboxes, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rX1fU7zlv5jW","colab_type":"code","colab":{}},"cell_type":"code","source":["# The German Traffic Sign Recognition Benchmark\n","train_images, train_files, train_signs, train_bboxes, train_labels = readImages('FullIJCNN2013', range(0,600), range(0,852))\n","test_images, test_files, test_signs, test_bboxes, test_labels = readImages('FullIJCNN2013', range(600,900), range(852,1213))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ReezQ_WZv5jY","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","# Show examples from each class\n","class_names = np.unique(train_labels)\n","num_classes = len(class_names)\n","fig = plt.figure(figsize=(8,8))\n","for i in range(num_classes):\n","    ax = fig.add_subplot(6, 9, 1 + i, xticks=[], yticks=[])\n","    ax.set_title(class_names[i])\n","    indices = np.where(np.isin(train_labels, class_names[i]))[0]\n","    plt.imshow(cv2.cvtColor(train_signs[int(np.random.choice(indices, 1))], cv2.COLOR_BGR2RGB))\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NAxooB6fv5jc","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.utils import shuffle\n","train_files, train_signs, train_bboxes, train_labels = shuffle(train_files, train_signs, train_bboxes, train_labels)\n","# plt.imshow(cv2.cvtColor(train_images.get(train_files[0])[0], cv2.COLOR_BGR2RGB))\n","# plt.show()\n","# plt.imshow(cv2.cvtColor(train_signs[0], cv2.COLOR_BGR2RGB))\n","# plt.show()\n","# print(train_bboxes[0])\n","# print(train_labels[0])\n","\n","# Data pre-processing\n","tr_signs = np.array(train_signs)[0:600]\n","tr_labels = np.array(train_labels)[0:600]\n","va_signs = np.array(train_signs)[600:852]\n","va_labels = np.array(train_labels)[600:852]\n","te_signs = np.array(test_signs)\n","te_labels = np.array(test_labels)\n","\n","tr_signs = tr_signs.astype('float32')\n","va_signs = va_signs.astype('float32')\n","te_signs = te_signs.astype('float32')\n","tr_signs /= 255.0\n","va_signs /= 255.0\n","te_signs /= 255.0\n","\n","from keras.utils import np_utils\n","tr_labels = np_utils.to_categorical(tr_labels, num_classes)\n","va_labels = np_utils.to_categorical(va_labels, num_classes)\n","te_labels = np_utils.to_categorical(te_labels, num_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"99l5hPfpv5jf","colab_type":"code","colab":{}},"cell_type":"code","source":["# Tensorboard\n","from time import time\n","from keras.callbacks import TensorBoard\n","tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tg4eTUx7v5jh","colab_type":"text"},"cell_type":"markdown","source":["## Assignment 3.3: Transfer learning"]},{"metadata":{"id":"W8zfXhTEv5ji","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.resnet50 import ResNet50\n","from keras.layers import Dense\n","from keras.models import Model\n","from keras.optimizers import Adam\n","\n","baseline = ResNet50(weights='imagenet', input_shape=(SIGN_SIZE[0], SIGN_SIZE[1], 3))\n","predictions = Dense(num_classes, activation='softmax')(baseline.layers[-2].output)\n","resnet = Model(inputs=baseline.input, outputs=predictions)\n","\n","opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","resnet.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","resnet.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VGPz9ZmKv5jl","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","datagen = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n","datagen.fit(tr_signs, augment=True)\n","\n","train_steps = int(len(tr_signs) / 16)\n","valid_steps = int(len(va_signs) / 16)\n","data = resnet.fit_generator(datagen.flow(tr_signs, tr_labels, batch_size=16), epochs=100, steps_per_epoch=train_steps, verbose=2, validation_data=(va_signs, va_labels), validation_steps=valid_steps, callbacks=[tensorboard])\n","\n","start = time()\n","loss, acc = resnet.evaluate(te_signs, te_labels, verbose=0)\n","end = time()\n","print('ResNet50 took ' + str(end - start) + ' seconds')\n","print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xqMw0qnuv5jo","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}